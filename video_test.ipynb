{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division # for puthon 2.7 to make result of division to be float\n",
    "import time                     # for measure time of procedure execution\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import imutils\n",
    "import skimage.transform\n",
    "import matplotlib as plt\n",
    "from sklearn.externals import joblib\n",
    "from skimage.feature import hog\n",
    "from skimage.exposure import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from header import *\n",
    "from train import *\n",
    "from image_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning():\n",
    "    print('*' * 20)\n",
    "    print('MACHINE LEARNING')\n",
    "    \n",
    "    execute('=' * 20 + '\\nTRAIN', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bounds(_mask, _img):\n",
    "    height, width, channels = _img.shape \n",
    "    contours, hierarchy = cv2.findContours(_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounds = []\n",
    "    for contour in contours:\n",
    "        [x, y, w, h] = bound = cv2.boundingRect(contour)\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "        ellipse_area = (math.pi * (w / 2) * (h / 2))\n",
    "        if(contour_area < 1000 or y > height*2/3):\n",
    "            cv2.drawContours(_mask, [contour], -1, 0, -1)\n",
    "            continue\n",
    "        if (0.4 < h / w < 2.5) and (w > 20) and (h > 20):\n",
    "            #if 0.8 < (contour_area / ellipse_area) < 1.2:\n",
    "                #if True:#check_is_circles(_img[y:y+h, x:x+w]):\n",
    "            bounds.append(bound)\n",
    "        else: \n",
    "            cv2.drawContours(_mask, [contour], -1, 0, -1)\n",
    "    return sorted(bounds, key=lambda x: (x[2] * x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_shape_template(bounds, templates, img):\n",
    "    methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "             'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "    \n",
    "    method = eval(methods[0])\n",
    "    crop_img = []\n",
    "    \n",
    "    for bound in bounds:\n",
    "        [x, y, w, h] = bound\n",
    "        image_found=img[y:y+h,x:x+w]\n",
    "        image_found = cv2.resize(image_found, (width, height))\n",
    "        crop_img.append(cv2.cvtColor(image_found, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "\n",
    "    for crop in crop_img:\n",
    "        for template in templates:\n",
    "            w, h, _ = template.shape\n",
    "            crop_cp = crop.copy()\n",
    "            plt.imshow(template)\n",
    "            temp = cv2.matchTemplate(crop_cp,template,method)\n",
    "            (minVal, maxVal, minLoc, (x, y)) = cv2.minMaxLoc(temp)\n",
    "            print (\"w = {}, h = {}, type = {}\".format(w, h, type(temp)))\n",
    "\n",
    "#     min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_sign(_img, _mask, _svm, _id):\n",
    "    bounds = find_bounds(_mask, _img)\n",
    "    _img = cv2.bitwise_and(_img, _img, mask=_mask)\n",
    "    for bound in bounds:\n",
    "        [x, y, w, h] = bound\n",
    "        \n",
    "        sign = _img[y:(y + h), x:(x + w)]\n",
    "        sign = cv2.resize(sign, (width, height))\n",
    "        class_id = classify_image(sign, _svm)\n",
    "        \n",
    "#         if class_id == _id:\n",
    "        return bound, class_id\n",
    "    return None, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svm():\n",
    "    pca = joblib.load('pca_and_svm/pca_40.pkl')\n",
    "    classifier = joblib.load('pca_and_svm/svm_rbf_scale.pkl')\n",
    "    return pca, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(_img, _svm, _templates, _templates_title, _frame_id, _info, pca, classifier):\n",
    "    img = ycrcb_equalize(_img)\n",
    "\n",
    "    orange_mask = get_mask(img, ['orange'])\n",
    "    orange_blur = cv2.medianBlur(orange_mask,3)\n",
    "    blue_mask = get_mask(img, ['blue'])\n",
    "    blue_blur = cv2.medianBlur(blue_mask,3)\n",
    "    #filled_img = image_fill(orange_mask)\n",
    "    #orange_blur = cv2.medianBlur(orange_mask,3)\n",
    "    wanted_id = 8\n",
    "    templates_id = blue_templates_id\n",
    "    temp_blurs = []\n",
    "    temp_blurs.append(orange_blur)\n",
    "    temp_blurs.append(blue_blur)\n",
    "    bounds = find_bounds(temp_blurs[0], _img)\n",
    "    #compare_shape_template(bounds, _templates, _img)\n",
    "    for temp_blur in temp_blurs:\n",
    "        bound, predict_id = recognize_sign(img, temp_blur, _svm, wanted_id)\n",
    "        if bound is not None:\n",
    "            [x, y, w, h] = bound\n",
    "            print(x,y,w,h)\n",
    "            cv2.rectangle(_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            img0 = img[x:x+w,y+h]\n",
    "            crop_image0=cv2.resize(img0, (64, 64))\n",
    "\n",
    "            ret,crop_image0 = cv2.threshold(crop_image0,127,255,cv2.THRESH_BINARY)\n",
    "            descriptor,imagehog  = hog(crop_image0, orientations=8,pixels_per_cell=(4,4),visualize=True)\n",
    "\n",
    "            descriptor_pca=pca.transform(descriptor.reshape(1,-1))\n",
    "            hog_image_rescaled = exposure.rescale_intensity(imagehog, in_range=(0, 10))\n",
    "            Predicted_Class=classifier.predict(descriptor_pca)[0]\n",
    "            cv2.putText(_img, Predicted_Class, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "    \n",
    "#     if predict_id == wanted_id:\n",
    "#         draw(_img, bound, _templates[predict_id - 1], _templates_title[predict_id - 1])\n",
    "#         [x, y, w, h] = bound\n",
    "#         _info.append([_frame_id, predict_id, x, y, x + w, y + h, '\\n'])\n",
    "            \n",
    "    cv2.imshow('result', _img)\n",
    "    cv2.imshow('filled_img', temp_blurs[0])\n",
    "    return _img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_1(_img, _svm, _templates, _templates_title, _frame_id, _info, pca, classifier):\n",
    "    img = ycrcb_equalize(_img)\n",
    "\n",
    "    orange_mask = get_mask(img, ['orange'])\n",
    "    blue_mask = get_mask(img, ['blue'])\n",
    "    #filled_img = image_fill(orange_mask)\n",
    "    orange_blur = cv2.medianBlur(orange_mask,3)\n",
    "    wanted_id = 8\n",
    "    templates_id = blue_templates_id\n",
    "    \n",
    "    bounds = find_bounds(orange_blur, _img)\n",
    "    #compare_shape_template(bounds, _templates, _img)\n",
    "    \n",
    "    bound, predict_id = recognize_sign(img, orange_blur, _svm, wanted_id)\n",
    "    if bound is not None:\n",
    "        [x, y, w, h] = bound\n",
    "        cv2.rectangle(_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        img0 = img[x:x+w,y+h]\n",
    "        crop_image0=cv2.resize(img0, (64, 64))\n",
    "\n",
    "        ret,crop_image0 = cv2.threshold(crop_image0,127,255,cv2.THRESH_BINARY)\n",
    "        descriptor,imagehog  = hog(crop_image0, orientations=8,pixels_per_cell=(4,4),visualize=True)\n",
    "\n",
    "        descriptor_pca=pca.transform(descriptor.reshape(1,-1))\n",
    "        hog_image_rescaled = exposure.rescale_intensity(imagehog, in_range=(0, 10))\n",
    "        Predicted_Class=classifier.predict(descriptor_pca)[0]\n",
    "        cv2.putText(_img, Predicted_Class, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "#     descriptor = hog.compute(_image)\n",
    "#     return int(_svm.predict(np.array([descriptor]))[1][0])\n",
    "#     if predict_id == wanted_id:\n",
    "#         draw(_img, bound, _templates[predict_id - 1], _templates_title[predict_id - 1])\n",
    "#         [x, y, w, h] = bound\n",
    "#         _info.append([_frame_id, predict_id, x, y, x + w, y + h, '\\n'])\n",
    "            \n",
    "    cv2.imshow('result', _img)\n",
    "    cv2.imshow('filled_img', orange_blur)\n",
    "    return _img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Image from Path:  ./image_and_video/ggggg.png\n",
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'cv2.HOGDescriptor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-593c24edb956>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morange_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#ret,crop_image0 = cv2.threshold(crop_image0,127,255,cv2.THRESH_BINARY)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdescriptor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimagehog\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mhog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_image0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpixels_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mdescriptor_pca\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'cv2.HOGDescriptor' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.exposure import exposure #for displaying th hog image.\n",
    "pca, classifier = load_svm()\n",
    "img_path = './image_and_video/ggggg.png'\n",
    "#img_path='0.jpg'\n",
    "# img = cv2.imread(img_path)\n",
    "# svm = execute('Loading model', cv2.ml.SVM_load, svm_model_file)\n",
    "# templates, templates_title = execute('Loading templates', load_templates)\n",
    "# info = []\n",
    "# frame_id = 3\n",
    "\n",
    "# frame = cv2.resize(img, (normal_width, normal_height))\n",
    "# r_m = process_image(frame, svm, templates, templates_title, frame_id, info)\n",
    "\n",
    "\n",
    "print ('Reading Image from Path: ',img_path)\n",
    "img = cv2.imread(img_path)\n",
    "orange_mask = get_mask(img, ['orange'])\n",
    "\n",
    "bounds = find_bounds(orange_mask, img)\n",
    "print (len(bounds))\n",
    "img0=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img0 = cv2.medianBlur(img0,3)\n",
    "crop_image0=cv2.resize(img0, (64, 64))\n",
    "plt.imshow(orange_mask)\n",
    "#ret,crop_image0 = cv2.threshold(crop_image0,127,255,cv2.THRESH_BINARY)\n",
    "descriptor,imagehog  = hog(crop_image0, orientations=8,pixels_per_cell=(4,4),visualize=True)\n",
    "\n",
    "descriptor_pca=pca.transform(descriptor.reshape(1,-1))\n",
    "hog_image_rescaled = exposure.rescale_intensity(imagehog, in_range=(0, 10))\n",
    "Predicted_Class=classifier.predict(descriptor_pca)[0]\n",
    "print (Predicted_Class)\n",
    "\n",
    "\n",
    "# w, h, _ = templates[5].shape\n",
    "# temp = cv2.matchTemplate(img,cv2.resize(templates[5],(100, 100)),cv2.TM_CCOEFF)\n",
    "# (minVal, maxVal, minLoc, (x, y)) = cv2.minMaxLoc(temp)\n",
    "#cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "#cv2.imshow(\"source\", img)\n",
    "\n",
    "#cv2.waitKey(0)\n",
    "plt.imshow(orange_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video():\n",
    "    print('*' * 20)\n",
    "    print('PROCESS VIDEO')\n",
    "\n",
    "    print('Init')\n",
    "    #print (svm_model_file)\n",
    "    svm = execute('Loading model', cv2.ml.SVM_load, svm_model_file)\n",
    "    templates, templates_title = execute('Loading templates', load_templates)\n",
    "\n",
    "    pca, classifier = load_svm()\n",
    "    \n",
    "    inp = cv2.VideoCapture(video_input)\n",
    "    video_width = int(inp.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    video_height = int(inp.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_fps = inp.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    print('Video resolution: (' + str(video_width) + ', ' + str(video_height) + ')')\n",
    "    print('Video fps:', video_fps)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(video_output, fourcc, video_fps, (normal_width, normal_height))\n",
    "    print('Video is running')\n",
    "    info = []\n",
    "\n",
    "    frame_id = 1\n",
    "    while inp.isOpened():\n",
    "        ret, frame = inp.read()\n",
    "        if (not ret) or (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            break\n",
    "        frame = cv2.resize(frame, (normal_width, normal_height))\n",
    "        processed_img = process_image(frame, svm, templates, templates_title, frame_id, info, pca, classifier)\n",
    "        out.write(processed_img)\n",
    "        frame_id += 1\n",
    "\n",
    "    with open(output, 'w') as f:\n",
    "        f.write(str(len(info)) + '\\n')\n",
    "        for elem in info:\n",
    "            f.write(' '.join(str(x) for x in elem))\n",
    "\n",
    "    inp.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print (\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "PROCESS VIDEO\n",
      "Init\n",
      "Loading model\n",
      "Time: 0.123038s\n",
      "-----\n",
      "Loading templates\n",
      "./templates\n",
      "Time: 0.007059s\n",
      "-----\n",
      "Video resolution: (1920, 1072)\n",
      "Video fps: 30.06318151971113\n",
      "Video is running\n",
      "389 281 37 49\n",
      "388 279 39 50\n",
      "385 276 39 50\n",
      "383 272 40 51\n",
      "380 269 40 53\n",
      "376 267 41 55\n",
      "371 265 42 56\n",
      "365 263 44 57\n",
      "360 261 45 60\n",
      "355 260 45 60\n",
      "349 258 48 61\n",
      "346 256 48 63\n",
      "342 253 50 66\n",
      "339 252 50 68\n",
      "335 250 52 69\n",
      "331 247 53 73\n",
      "325 244 57 76\n",
      "319 242 57 77\n",
      "309 238 61 81\n",
      "300 235 63 83\n",
      "291 229 64 86\n",
      "280 224 66 90\n",
      "267 219 69 92\n",
      "253 212 72 97\n",
      "240 206 76 101\n",
      "229 199 80 105\n",
      "215 192 84 112\n",
      "200 184 89 117\n",
      "185 174 94 122\n",
      "167 164 100 130\n",
      "147 152 105 137\n",
      "121 138 113 146\n",
      "89 121 121 157\n",
      "53 102 129 169\n",
      "11 81 140 182\n",
      "0 56 118 199\n",
      "361 278 40 48\n",
      "359 277 41 48\n",
      "357 275 40 49\n",
      "351 274 40 51\n",
      "345 272 39 52\n",
      "337 270 40 54\n",
      "330 270 41 54\n",
      "324 269 44 55\n",
      "319 268 44 56\n",
      "316 266 45 59\n",
      "314 264 45 60\n",
      "311 262 46 61\n",
      "307 260 48 63\n",
      "303 258 49 65\n",
      "300 254 51 68\n",
      "297 251 52 70\n",
      "292 249 55 71\n",
      "288 245 56 75\n",
      "283 243 58 76\n",
      "279 239 60 79\n",
      "274 235 62 81\n",
      "269 231 63 84\n",
      "263 226 66 88\n",
      "255 220 69 92\n",
      "248 215 71 96\n",
      "239 209 75 100\n",
      "231 203 77 103\n",
      "219 196 82 109\n",
      "209 188 85 114\n",
      "195 179 90 120\n",
      "181 170 95 127\n",
      "163 160 101 134\n",
      "144 149 107 141\n",
      "123 136 112 150\n",
      "97 122 120 159\n",
      "68 105 128 171\n",
      "35 86 137 184\n",
      "0 65 144 196\n",
      "0 37 109 216\n",
      "214 294 61 36\n",
      "209 292 64 38\n",
      "335 279 35 54\n",
      "205 290 66 40\n",
      "334 276 36 57\n",
      "201 288 69 41\n",
      "333 271 36 62\n",
      "195 286 73 43\n",
      "331 271 37 61\n",
      "191 283 75 46\n",
      "329 270 38 61\n",
      "184 281 79 47\n",
      "327 270 39 62\n",
      "179 279 82 49\n",
      "325 269 40 63\n",
      "172 278 85 51\n",
      "322 268 41 64\n",
      "165 277 90 52\n",
      "319 270 42 61\n",
      "156 275 95 53\n",
      "315 266 43 65\n",
      "147 274 100 55\n",
      "312 264 44 67\n",
      "139 270 104 59\n",
      "309 264 45 66\n",
      "129 268 110 60\n",
      "305 261 46 69\n",
      "119 265 115 62\n",
      "301 260 51 69\n",
      "108 262 121 65\n",
      "295 259 52 70\n",
      "94 259 130 118\n",
      "292 258 57 71\n",
      "81 255 139 123\n",
      "287 256 52 72\n",
      "68 251 147 127\n",
      "283 255 53 72\n",
      "54 247 156 132\n",
      "277 252 57 75\n",
      "38 243 166 137\n",
      "271 243 56 83\n",
      "19 238 177 143\n",
      "263 241 61 84\n",
      "0 232 186 150\n",
      "257 239 61 85\n",
      "0 229 179 153\n",
      "251 236 62 87\n",
      "0 231 172 152\n",
      "242 225 70 96\n",
      "0 232 164 152\n",
      "231 225 95 95\n",
      "0 233 155 152\n",
      "223 218 81 101\n",
      "0 236 144 150\n",
      "214 217 88 100\n",
      "0 235 138 152\n",
      "204 212 98 103\n",
      "0 235 131 101\n",
      "193 205 84 108\n",
      "0 237 123 98\n",
      "181 198 84 113\n",
      "0 240 113 94\n",
      "169 191 90 118\n",
      "0 238 103 97\n",
      "155 182 100 124\n",
      "0 238 93 98\n",
      "139 172 112 131\n",
      "0 240 81 98\n",
      "121 160 127 139\n",
      "0 240 68 92\n",
      "100 148 139 147\n",
      "79 133 117 156\n",
      "0 240 39 57\n",
      "53 117 120 167\n",
      "23 99 126 178\n",
      "0 79 128 190\n",
      "0 55 93 206\n",
      "159 317 74 80\n",
      "136 313 81 88\n",
      "108 306 89 98\n",
      "75 301 98 105\n",
      "35 290 109 119\n",
      "0 273 110 142\n",
      "0 274 66 132\n",
      "355 317 36 52\n",
      "353 316 38 51\n",
      "352 315 39 53\n",
      "351 314 40 53\n",
      "349 312 40 56\n",
      "348 310 41 57\n",
      "345 308 42 58\n",
      "342 305 43 60\n",
      "338 302 46 62\n",
      "335 299 44 64\n",
      "330 297 46 65\n",
      "325 295 48 67\n",
      "321 294 48 68\n",
      "317 292 50 70\n",
      "311 289 52 72\n",
      "305 288 54 73\n",
      "297 285 56 75\n",
      "289 281 56 78\n",
      "279 278 58 80\n",
      "268 275 61 83\n",
      "259 271 63 88\n",
      "249 268 67 90\n",
      "241 264 69 93\n",
      "233 260 71 97\n",
      "221 254 76 103\n",
      "211 250 79 105\n",
      "201 243 85 111\n",
      "190 236 87 117\n",
      "177 229 91 121\n",
      "162 220 98 128\n",
      "147 211 102 135\n",
      "128 201 108 139\n",
      "108 189 115 149\n",
      "87 175 121 158\n",
      "60 159 131 170\n",
      "29 142 140 179\n",
      "0 120 146 194\n",
      "0 94 116 210\n",
      "0 68 79 194\n",
      "69 301 36 53\n",
      "51 295 38 61\n",
      "32 289 41 74\n",
      "12 281 43 78\n",
      "0 273 34 82\n",
      "233 320 35 47\n",
      "228 319 35 48\n",
      "222 319 37 48\n",
      "217 317 37 50\n",
      "211 315 39 51\n",
      "206 312 40 53\n",
      "201 310 40 54\n",
      "195 307 42 56\n",
      "189 304 43 58\n",
      "182 301 45 60\n",
      "179 299 45 61\n",
      "167 292 47 63\n",
      "158 287 49 65\n",
      "149 280 51 67\n",
      "139 273 52 69\n",
      "127 265 54 71\n",
      "113 257 58 73\n",
      "100 249 59 76\n",
      "87 243 61 78\n",
      "72 236 65 81\n",
      "57 228 68 85\n",
      "41 220 71 89\n",
      "23 211 74 92\n",
      "3 201 79 97\n",
      "0 190 64 102\n",
      "0 179 44 105\n",
      "149 235 44 66\n",
      "135 231 47 67\n",
      "121 224 48 71\n",
      "104 212 51 80\n",
      "83 204 57 85\n",
      "61 195 60 90\n",
      "35 184 64 97\n",
      "5 175 70 103\n",
      "0 162 48 110\n",
      "293 295 38 50\n",
      "291 294 38 50\n",
      "286 291 43 53\n",
      "286 288 40 52\n",
      "285 286 40 54\n",
      "281 281 42 56\n",
      "279 276 43 57\n",
      "274 271 45 59\n",
      "271 265 44 60\n",
      "266 261 47 63\n",
      "262 259 49 64\n",
      "257 256 52 67\n",
      "253 254 54 69\n",
      "249 252 52 71\n",
      "243 250 56 73\n",
      "237 247 58 75\n",
      "229 245 60 78\n",
      "221 241 62 82\n",
      "213 237 64 84\n",
      "203 233 68 89\n",
      "194 227 71 94\n",
      "184 223 76 95\n",
      "173 218 78 99\n",
      "161 211 82 104\n",
      "147 206 87 108\n",
      "133 199 90 114\n",
      "118 191 93 121\n",
      "100 184 99 127\n",
      "80 174 106 135\n",
      "56 163 111 143\n",
      "27 149 119 155\n",
      "0 135 121 164\n",
      "0 119 93 177\n",
      "315 311 39 56\n",
      "313 308 41 58\n",
      "312 304 41 61\n",
      "311 301 41 62\n",
      "309 298 41 63\n",
      "305 295 44 64\n",
      "301 290 46 67\n",
      "297 287 48 68\n",
      "290 282 53 71\n",
      "283 277 53 73\n",
      "277 269 55 75\n",
      "267 260 59 78\n",
      "256 251 61 81\n",
      "243 243 65 83\n",
      "232 236 67 88\n",
      "221 231 69 91\n",
      "212 226 73 95\n",
      "201 219 77 101\n",
      "190 213 81 104\n",
      "179 206 84 108\n",
      "171 201 88 113\n",
      "165 198 90 114\n",
      "151 188 96 121\n",
      "135 177 102 128\n",
      "117 165 107 136\n",
      "94 152 116 144\n",
      "55 129 128 158\n",
      "24 111 137 170\n",
      "0 90 137 183\n",
      "0 65 109 198\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "process_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_sign",
   "language": "python",
   "name": "traffic_sign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
